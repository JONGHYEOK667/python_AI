{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3d87ba-bb2f-4871-8411-1613ef585c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "def set_seed(seed):\n",
    "    # Python random 모듈의 시드 고정\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy의 시드 고정\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch의 시드 고정 (CPU 연산)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # PyTorch의 시드 고정 (CUDA 연산)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # 여러 개의 GPU를 사용하는 경우\n",
    "    \n",
    "    # 재현성을 위해 일부 설정 비활성화\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 사용 예시\n",
    "#set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70806a-4939-452c-8707-d732f409623f",
   "metadata": {},
   "source": [
    "# STEP 0. GPU 유무에 따른 Device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a82463-c50f-4cd8-981d-0daf887359b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU가 사용 가능합니다. 현재 사용중인 GPU 수: 1\n",
      "현재 디바이스 이름: NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU가 사용 가능합니다. 현재 사용중인 GPU 수:\", torch.cuda.device_count())\n",
    "    print(\"현재 디바이스 이름:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"GPU를 사용할 수 없습니다. CPU를 사용합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e198c08-15fc-49a6-8ccf-ed1553d2a608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(\"device : {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e597cb-8cc6-4bd6-b365-a0c80f530145",
   "metadata": {},
   "source": [
    "# STEP 1.  데이터 로드 및 train/validation/test 데이터설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4bea59-b764-48da-a6c8-07b455e9eda6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./DataSet\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 전처리: ToTensor 변환을 적용합니다.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 2. CIFAR-10 데이터셋 다운로드 및 로드\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./DataSet\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./DataSet\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd1d3ed-a047-4ef0-a3c5-e1bcce21a83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터셋 크기 : 42500\n",
      "validation 데이터셋 크기 : 7500\n",
      "test 데이터셋 크기 : 10000\n"
     ]
    }
   ],
   "source": [
    "# 3. 학습 데이터셋을 훈련용과 검증용으로 분할\n",
    "train_dataset_size = int(len(train_dataset)*0.85)\n",
    "validation_dataset_size = len(train_dataset) - train_dataset_size\n",
    "\n",
    "train_dataset, validation_dataset = random_split(train_dataset,[train_dataset_size, validation_dataset_size])\n",
    "\n",
    "print(\"train 데이터셋 크기 : {}\".format(len(train_dataset)))\n",
    "print(\"validation 데이터셋 크기 : {}\".format(len(validation_dataset)))\n",
    "print(\"test 데이터셋 크기 : {}\".format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbcf0cf-393f-4e68-85e0-5e4482ad1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 256\n",
    "\n",
    "# 학습 데이터 로더 생성\n",
    "# batch_size: 한 번에 불러올 데이터 수 (예, 64개)\n",
    "# shuffle: 학습 시 데이터 순서를 무작위로 섞어 모델의 일반화 성능을 높임\n",
    "# num_workers: 데이터를 불러올 때 사용할 subprocess 수 (환경에 따라 조정)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True, num_workers=8)\n",
    "\n",
    "# 검증 데이터 로더 생성\n",
    "# 평가 시에는 데이터 순서를 섞을 필요가 없으므로 shuffle=False로 설정\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batchSize, shuffle=False, num_workers=8)\n",
    "\n",
    "# 테스트 데이터 로더 생성 (검증과 동일한 설정)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchSize, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0797be1f-8766-4156-acac-be641d9523ef",
   "metadata": {},
   "source": [
    "# STEP 2. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1e09a3-888c-4948-8961-fd3af55a8f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "model : Model(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout25): Dropout(p=0.25, inplace=False)\n",
      "  (dropout50): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "---------------------------------------------------------------------\n",
      "loss_function : CrossEntropyLoss()\n",
      "---------------------------------------------------------------------\n",
      "optimizer : Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# CNN 모델 클래스 정의 (nn.Module을 상속받음)\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. 첫 번째 합성곱(Convolution) 계층\n",
    "        # 입력 채널: 3 (RGB 이미지), 출력 채널: 32, 커널 크기: 3x3, 패딩: 1 (출력 크기를 유지)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 2. 두 번째 합성곱 계층\n",
    "        # 입력 채널: 32 (앞 계층의 출력), 출력 채널: 64, 커널 크기: 3x3, 패딩: 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        # 3. 최대 풀링 계층\n",
    "        # 2x2 영역에서 최대값을 취해 이미지의 크기를 절반으로 줄임 (stride=2)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 4. 완전 연결(fully-connected, fc) 계층\n",
    "        # 첫 번째 fc 계층: 평탄화(flatten)된 8*8*64 차원을 128 차원으로 변환\n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 128)\n",
    "        # 두 번째 fc 계층: 128 차원을 10개의 클래스에 대응하는 출력으로 변환\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        # 5. 드롭아웃 계층\n",
    "        # dropout25: 25%의 확률로 일부 뉴런을 임의로 꺼서 과적합을 방지\n",
    "        self.dropout25 = nn.Dropout(p=0.25)\n",
    "        # dropout50: 50%의 확률로 일부 뉴런을 임의로 꺼서 과적합을 방지\n",
    "        self.dropout50 = nn.Dropout(p=0.5)\n",
    "\n",
    "    # 순전파(forward) 함수 정의: 입력 x가 모델을 통과하는 과정을 기술\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 합성곱 계층 통과\n",
    "        x = self.conv1(x)\n",
    "        # ReLU 활성화 함수 적용하여 음수 값은 0으로 만듦\n",
    "        x = torch.relu(x)\n",
    "        # 최대 풀링 계층 적용하여 특징 맵 크기를 줄임\n",
    "        x = self.pooling(x)\n",
    "        # 25% 드롭아웃 적용하여 일부 뉴런을 임의로 끔\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "        # 두 번째 합성곱 계층 통과\n",
    "        x = self.conv2(x)\n",
    "        # ReLU 활성화 함수 적용\n",
    "        x = torch.relu(x)\n",
    "        # 다시 최대 풀링 계층 적용 (출력 크기 더 줄어듦)\n",
    "        x = self.pooling(x)\n",
    "        # 또 다시 25% 드롭아웃 적용\n",
    "        x = self.dropout25(x)\n",
    "\n",
    "        # 다차원 텐서를 1차원으로 평탄화(flatten)\n",
    "        # -1은 배치 크기를 자동으로 맞춰줌 (여기서 8x8x64는 풀링 후의 차원)\n",
    "        x = x.view(-1, 8 * 8 * 64)\n",
    "\n",
    "        # 첫 번째 완전 연결 계층 통과\n",
    "        x = self.fc1(x)\n",
    "        # ReLU 활성화 함수 적용\n",
    "        x = torch.relu(x)\n",
    "        # 50% 드롭아웃 적용 (더 강한 과적합 방지)\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        # 두 번째 완전 연결 계층 (출력 계층) 전에도 50% 드롭아웃 적용\n",
    "        logits = self.dropout50(x)\n",
    "\n",
    "        # 최종 출력 (각 클래스에 대한 점수 반환)\n",
    "        return logits\n",
    "\n",
    "# 모델 객체 생성 후, 지정한 DEVICE(\"cuda\" 또는 \"cpu\")로 이동\n",
    "model = Model().to(DEVICE)\n",
    "\n",
    "# 분류 문제에서 많이 사용하는 손실 함수 (교차 엔트로피 손실 함수) 정의\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam 옵티마이저 정의 (모델 파라미터 업데이트, 학습률은 0.001로 설정)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 정보를 출력\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"model : {}\".format(model))\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"loss_function : {}\".format(loss_function))\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"optimizer : {}\".format(optimizer))\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a260b8c0-384c-42dd-b333-4bdd069b4280",
   "metadata": {},
   "source": [
    "# STEP 3. train/evaluate 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a71d9b-6417-4fcc-9799-990b9c3a0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(dataloader, model, loss_function, optimizer):\n",
    "    # 1. 모델을 학습 모드로 전환합니다.\n",
    "    #    - model.train()을 호출하면 dropout이나 batch normalization과 같은 계층들이 학습 모드에 맞게 동작합니다.\n",
    "    model.train()\n",
    "\n",
    "    # 2. 학습 과정 동안 누적할 변수들을 초기화합니다.\n",
    "    #    - train_loss_sum: 모든 배치(batch)의 손실(loss) 값을 누적할 변수 (float)\n",
    "    #    - train_correct: 모든 배치에서 예측이 맞은 샘플 수를 누적할 변수 (int)\n",
    "    #    - train_total: 전체 샘플 수를 누적할 변수 (int)\n",
    "    train_loss_sum = train_correct = train_total = 0\n",
    "\n",
    "    # 3. 전체 배치의 수를 계산합니다.\n",
    "    #    - dataloader는 DataLoader 객체이며, len(dataloader)는 전체 배치의 개수 (int)를 반환합니다.\n",
    "    total_train_batch = len(dataloader)\n",
    "\n",
    "    # 4. DataLoader를 통해 배치 단위로 데이터를 순회합니다.\n",
    "    #    - images: 한 배치에 포함된 이미지 텐서, 보통 shape는 [batch_size, 채널, 높이, 너비] (예: [64, 3, 32, 32])\n",
    "    #    - labels: 해당 이미지들의 정답 레이블 텐서, 보통 shape는 [batch_size] (예: [64])\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        # 5. 현재 배치의 데이터를 지정한 DEVICE(GPU 또는 CPU)로 이동시킵니다.\n",
    "        #    - x_train: images 데이터를 DEVICE로 이동 (동일한 shape, 데이터 타입은 torch.Tensor)\n",
    "        #    - y_train: labels 데이터를 DEVICE로 이동 (동일한 shape, 데이터 타입은 torch.Tensor)\n",
    "        x_train = images.to(DEVICE)\n",
    "        y_train = labels.to(DEVICE)\n",
    "\n",
    "        # 6. 모델에 입력 데이터를 넣어 예측 결과를 구합니다.\n",
    "        #    - outputs: 모델의 출력 텐서, 보통 shape는 [batch_size, 클래스 수] (예: [64, 10])\n",
    "        outputs = model(x_train)\n",
    "\n",
    "        # 7. 모델의 출력과 실제 정답을 비교하여 손실(loss)를 계산합니다.\n",
    "        #    - loss_function: 주로 nn.CrossEntropyLoss() 등 분류 손실 함수를 사용\n",
    "        #    - loss: 현재 배치의 손실 값 (torch.Tensor, 스칼라 형태)\n",
    "        loss = loss_function(outputs, y_train)\n",
    "\n",
    "        # 8. 옵티마이저의 기울기(gradient)를 0으로 초기화합니다.\n",
    "        #    - 기울기가 누적되어 이전 배치의 정보가 남는 것을 방지합니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 9. 역전파(backward propagation)를 수행하여 기울기를 계산합니다.\n",
    "        loss.backward()\n",
    "\n",
    "        # 10. 옵티마이저를 통해 모델 파라미터를 업데이트합니다.\n",
    "        optimizer.step()\n",
    "\n",
    "        # 11. 현재 배치의 손실 값을 train_loss_sum에 누적합니다.\n",
    "        #     - loss.item()은 손실 텐서에서 파이썬 스칼라 값을 추출합니다.\n",
    "        train_loss_sum += loss.item()\n",
    "\n",
    "        # 12. 현재 배치의 총 샘플 수를 train_total에 누적합니다.\n",
    "        #     - y_train.size(0)은 배치의 첫 번째 차원(샘플 수)를 반환합니다.\n",
    "        train_total += y_train.size(0)\n",
    "\n",
    "        # 13. 현재 배치에서 맞춘 샘플 수를 계산하여 train_correct에 누적합니다.\n",
    "        #     - torch.argmax(outputs, 1): 각 샘플별로 예측 결과(outputs) 중 가장 큰 값을 가진 인덱스(예측 클래스)를 반환\n",
    "        #     - (torch.argmax(outputs, 1) == y_train): 예측한 클래스와 실제 라벨이 같은지를 비교하여 Boolean 텐서를 만듦\n",
    "        #     - .sum(): True(맞은 샘플)의 개수를 셈 (Tensor형태)\n",
    "        #     - .item(): 그 결과를 파이썬 스칼라 값으로 변환\n",
    "        train_correct += ((torch.argmax(outputs, 1) == y_train)).sum().item()\n",
    "\n",
    "    # 14. 평균 손실(train_avg_loss)을 계산합니다.\n",
    "    #     - train_loss_sum: 모든 배치에서의 손실 합계 (float)\n",
    "    #     - total_train_batch: 전체 배치 수 (int)\n",
    "    #     - 두 값을 나누어 배치당 평균 손실을 구함\n",
    "    train_avg_loss = train_loss_sum / total_train_batch\n",
    "\n",
    "    # 15. 평균 정확도(train_avg_accuracy)를 계산합니다.\n",
    "    #     - train_correct: 맞은 샘플의 총 개수 (int)\n",
    "    #     - train_total: 전체 샘플 수 (int)\n",
    "    #     - (train_correct / train_total)은 정확도를 소수점으로 나타내며, 여기에 100을 곱해 백분율로 표현합니다.\n",
    "    train_avg_accuracy = 100 * train_correct / train_total\n",
    "\n",
    "    # 16. 최종적으로 배치 평균 손실과 전체 정확도를 튜플 형태로 반환합니다.\n",
    "    return (train_avg_loss, train_avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98330d25-7a14-4c88-8886-593e30d6f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(dataloader, model, loss_function, optimizer):\n",
    "    # 1. 모델을 평가 모드로 전환합니다.\n",
    "    #    - model.eval()은 드롭아웃, 배치 정규화 등 특정 계층들이 평가용으로 동작하도록 설정합니다.\n",
    "    model.eval()\n",
    "\n",
    "    # 2. 평가 시에는 그래디언트(gradient)를 계산하지 않도록 설정합니다.\n",
    "    #    - with torch.no_grad() 블록 안에서는 backward 연산이 수행되지 않아 메모리 사용량과 연산 속도를 최적화할 수 있습니다.\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 3. 평가 동안 누적할 변수를 초기화합니다.\n",
    "        #    - val_loss_sum: 각 배치(batch)에서 계산된 손실(loss) 값의 총합 (float)\n",
    "        #    - val_correct: 맞게 예측한 샘플 수를 누적 (int)\n",
    "        #    - val_total: 전체 평가에 사용된 샘플의 총 개수 (int)\n",
    "        val_loss_sum = val_correct = val_total = 0\n",
    "\n",
    "        # 4. 전체 평가 배치(batch)의 개수를 계산합니다.\n",
    "        #    - dataloader의 길이는 전체 배치의 수를 의미합니다.\n",
    "        total_val_batch = len(dataloader)\n",
    "\n",
    "        # 5. DataLoader를 이용해 평가 데이터를 배치 단위로 순회합니다.\n",
    "        #    - images: 각 배치에 포함된 이미지 텐서 (일반적으로 shape: [batch_size, 채널, 높이, 너비], 예: [64, 3, 32, 32])\n",
    "        #    - labels: 각 이미지에 해당하는 정답 레이블 텐서 (일반적으로 shape: [batch_size], 예: [64])\n",
    "        for images, labels in dataloader:\n",
    "\n",
    "            # 6. 현재 배치의 데이터를 지정한 DEVICE(GPU 또는 CPU)로 이동합니다.\n",
    "            #    - x_val: images 데이터를 DEVICE로 이동 (동일한 shape, torch.Tensor)\n",
    "            #    - y_val: labels 데이터를 DEVICE로 이동 (동일한 shape, torch.Tensor)\n",
    "            x_val = images.to(DEVICE)\n",
    "            y_val = labels.to(DEVICE)\n",
    "\n",
    "            # 7. 모델에 평가 데이터(x_val)를 입력하여 예측 결과(outputs)를 얻습니다.\n",
    "            #    - outputs: 모델의 출력 텐서 (일반적으로 shape: [batch_size, 클래스 수], 예: [64, 10])\n",
    "            outputs = model(x_val)\n",
    "\n",
    "            # 8. 모델의 출력(outputs)과 실제 정답(y_val)을 비교하여 손실(loss)을 계산합니다.\n",
    "            #    - loss_function은 주로 nn.CrossEntropyLoss() 등 분류 문제에서 사용되는 손실 함수입니다.\n",
    "            loss = loss_function(outputs, y_val)\n",
    "\n",
    "            # 9. 현재 배치의 손실 값을 스칼라 값으로 변환하여 누적합니다.\n",
    "            #    - loss.item()은 텐서(loss)를 파이썬 스칼라 값으로 변환합니다.\n",
    "            val_loss_sum += loss.item()\n",
    "\n",
    "            # 10. 현재 배치의 총 샘플 수를 누적합니다.\n",
    "            #     - y_val.size(0)은 현재 배치의 샘플 수(배치 크기)를 반환합니다.\n",
    "            val_total += y_val.size(0)\n",
    "\n",
    "            # 11. 현재 배치에서 맞춘 샘플 수를 계산하여 누적합니다.\n",
    "            #     - torch.argmax(outputs, 1)은 각 샘플별로 가장 높은 점수를 가진 인덱스(예측 클래스)를 반환합니다.\n",
    "            #     - (torch.argmax(outputs, 1) == y_val)는 예측 클래스와 실제 레이블을 비교하여 Boolean 텐서를 생성합니다.\n",
    "            #     - .sum()을 통해 True(맞은 샘플)의 개수를 계산하고, .item()으로 파이썬 스칼라 값으로 변환합니다.\n",
    "            val_correct += ((torch.argmax(outputs, 1) == y_val)).sum().item()\n",
    "\n",
    "        # 12. 평가 전체 배치에 대한 평균 손실(val_avg_loss)을 계산합니다.\n",
    "        #     - 전체 손실의 합(val_loss_sum)을 전체 배치 수(total_val_batch)로 나눕니다.\n",
    "        val_avg_loss = val_loss_sum / total_val_batch\n",
    "\n",
    "        # 13. 전체 평가 데이터에 대한 평균 정확도(val_avg_accuracy)를 계산합니다.\n",
    "        #     - 전체 맞은 샘플 수(val_correct)를 전체 샘플 수(val_total)로 나눈 후, 100을 곱해 백분율(%)로 표현합니다.\n",
    "        val_avg_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    # 14. 최종적으로 평가 모드에서 계산된 평균 손실과 평균 정확도를 튜플 형태로 반환합니다.\n",
    "    return (val_avg_loss, val_avg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb65997-4399-4383-8a2f-96e8eabe493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(dataloader, model): # model_eval과 동일함\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        test_loss_sum = test_correct = test_total = 0\n",
    "\n",
    "        total_test_batch = len(dataloader)\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "\n",
    "            x_test = images.to(DEVICE)\n",
    "            y_test = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(x_test)\n",
    "            loss = loss_function(outputs, y_test)\n",
    "\n",
    "            test_loss_sum += loss.item()\n",
    "\n",
    "            test_total += y_test.size(0)\n",
    "            test_correct += ((torch.argmax(outputs, 1)==y_test)).sum().item()\n",
    "\n",
    "        test_avg_loss = test_loss_sum / total_test_batch\n",
    "        test_avg_accuracy = 100*test_correct / test_total\n",
    "\n",
    "        print('accuracy:', test_avg_accuracy)\n",
    "        print('loss:', test_avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833703a-d2cb-49a1-9180-c0e738d5e8c3",
   "metadata": {},
   "source": [
    "# STEP 4. 학습 수행 및 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac4172-d4ff-4cc6-a0bc-33ee7a4cecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 01 epoch_time = 77.28 sec  train_loss = 4.38  train_acc = 15.18  val_loss = 4.16  val_acc = 34.77 \n",
      "epoch: 02 epoch_time = 76.92 sec  train_loss = 4.29  train_acc = 18.15  val_loss = 4.09  val_acc = 41.75 \n",
      "epoch: 03 epoch_time = 76.27 sec  train_loss = 4.25  train_acc = 19.22  val_loss = 4.06  val_acc = 44.68 \n",
      "epoch: 04 epoch_time = 76.29 sec  train_loss = 4.23  train_acc = 19.80  val_loss = 4.08  val_acc = 49.69 \n",
      "epoch: 05 epoch_time = 76.46 sec  train_loss = 4.21  train_acc = 20.18  val_loss = 4.08  val_acc = 50.35 \n",
      "epoch: 06 epoch_time = 76.31 sec  train_loss = 4.20  train_acc = 20.42  val_loss = 3.96  val_acc = 53.27 \n",
      "epoch: 07 epoch_time = 76.46 sec  train_loss = 4.18  train_acc = 20.74  val_loss = 3.89  val_acc = 52.36 \n",
      "epoch: 08 epoch_time = 76.49 sec  train_loss = 4.19  train_acc = 20.82  val_loss = 4.01  val_acc = 55.19 \n",
      "epoch: 09 epoch_time = 76.26 sec  train_loss = 4.17  train_acc = 20.80  val_loss = 3.95  val_acc = 55.05 \n",
      "epoch: 10 epoch_time = 76.30 sec  train_loss = 4.15  train_acc = 21.34  val_loss = 3.93  val_acc = 56.12 \n",
      "epoch: 11 epoch_time = 76.48 sec  train_loss = 4.16  train_acc = 21.11  val_loss = 3.88  val_acc = 58.55 \n",
      "epoch: 12 epoch_time = 76.22 sec  train_loss = 4.13  train_acc = 21.85  val_loss = 3.84  val_acc = 58.55 \n",
      "epoch: 13 epoch_time = 76.97 sec  train_loss = 4.13  train_acc = 21.52  val_loss = 3.89  val_acc = 60.61 \n",
      "epoch: 14 epoch_time = 76.27 sec  train_loss = 4.15  train_acc = 21.55  val_loss = 3.91  val_acc = 60.75 \n",
      "epoch: 15 epoch_time = 76.28 sec  train_loss = 4.13  train_acc = 21.90  val_loss = 3.93  val_acc = 59.88 \n",
      "epoch: 16 epoch_time = 76.25 sec  train_loss = 4.13  train_acc = 21.78  val_loss = 3.94  val_acc = 59.05 \n",
      "epoch: 17 epoch_time = 76.29 sec  train_loss = 4.13  train_acc = 21.87  val_loss = 3.75  val_acc = 52.76 \n",
      "epoch: 18 epoch_time = 76.46 sec  train_loss = 4.15  train_acc = 21.52  val_loss = 3.86  val_acc = 62.00 \n",
      "epoch: 19 epoch_time = 76.25 sec  train_loss = 4.12  train_acc = 22.06  val_loss = 3.87  val_acc = 62.24 \n",
      "epoch: 20 epoch_time = 76.48 sec  train_loss = 4.11  train_acc = 22.53  val_loss = 3.80  val_acc = 61.21 \n",
      "epoch: 21 epoch_time = 76.46 sec  train_loss = 4.12  train_acc = 22.37  val_loss = 3.86  val_acc = 62.53 \n",
      "epoch: 22 epoch_time = 76.45 sec  train_loss = 4.11  train_acc = 22.36  val_loss = 3.82  val_acc = 62.95 \n",
      "epoch: 23 epoch_time = 76.51 sec  train_loss = 4.09  train_acc = 22.68  val_loss = 3.78  val_acc = 63.60 \n",
      "epoch: 24 epoch_time = 76.50 sec  train_loss = 4.12  train_acc = 22.42  val_loss = 3.91  val_acc = 62.61 \n",
      "epoch: 25 epoch_time = 76.24 sec  train_loss = 4.12  train_acc = 22.33  val_loss = 3.94  val_acc = 62.25 \n",
      "epoch: 26 epoch_time = 76.68 sec  train_loss = 4.11  train_acc = 22.30  val_loss = 3.78  val_acc = 62.12 \n",
      "epoch: 27 epoch_time = 76.31 sec  train_loss = 4.10  train_acc = 22.89  val_loss = 3.75  val_acc = 64.20 \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  # datetime 모듈을 사용하여 시간 측정을 수행합니다.\n",
    "\n",
    "# 학습 및 평가 결과를 저장할 리스트들 (각 epoch마다 손실과 정확도를 기록)\n",
    "train_loss_list = []       # 각 epoch의 평균 학습 손실 (float) 저장\n",
    "train_accuracy_list = []   # 각 epoch의 평균 학습 정확도 (float) 저장\n",
    "\n",
    "val_loss_list = []         # 각 epoch의 평균 검증 손실 (float) 저장\n",
    "val_accuracy_list = []     # 각 epoch의 평균 검증 정확도 (float) 저장\n",
    "\n",
    "# 전체 학습 시작 시간 기록 (전체 코드가 실행되는 시작 시각)\n",
    "start_time = datetime.now()\n",
    "\n",
    "EPOCHS = 30  # 학습할 epoch(반복) 수, 정수형\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -----------------------------------------------\n",
    "    # 각 epoch 시작 시각을 기록합니다.\n",
    "    epoch_start = datetime.now()  # epoch 시작 시간 (datetime 객체)\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    # =================== model train =================== #\n",
    "    # train_loader: DataLoader 객체, 배치 단위의 학습 데이터를 제공합니다.\n",
    "    # model_train 함수는 학습 데이터를 이용해 모델 파라미터를 업데이트하고,\n",
    "    # 평균 손실(train_avg_loss)과 평균 정확도(train_avg_accuracy)를 반환합니다.\n",
    "    train_avg_loss, train_avg_accuracy = model_train(train_loader, model, loss_function, optimizer)\n",
    "\n",
    "    \n",
    "    # 반환된 손실과 정확도를 리스트에 저장합니다.\n",
    "    train_loss_list.append(train_avg_loss)\n",
    "    train_accuracy_list.append(train_avg_accuracy)\n",
    "    # ==================================================== #\n",
    "\n",
    "    # =================== model evaluation =================== #\n",
    "    # validation_loader: DataLoader 객체, 배치 단위의 검증 데이터를 제공합니다.\n",
    "    # model_evaluate 함수는 검증 데이터를 이용해 모델의 성능(평균 손실과 정확도)을 평가합니다.\n",
    "    val_avg_loss, val_avg_accuracy = model_evaluate(validation_loader, model, loss_function, optimizer)\n",
    "    \n",
    "    # 반환된 검증 손실과 정확도를 리스트에 저장합니다.\n",
    "    val_loss_list.append(val_avg_loss)\n",
    "    val_accuracy_list.append(val_avg_accuracy)\n",
    "    # ======================================================= #\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 각 epoch 종료 시각을 기록하고, 해당 epoch에 걸린 시간을 계산합니다.\n",
    "    epoch_end = datetime.now()           # epoch 종료 시간 (datetime 객체)\n",
    "    epoch_elapsed = epoch_end - epoch_start  # epoch 소요 시간 (timedelta 객체)\n",
    "    epoch_seconds = epoch_elapsed.total_seconds() # 소요 시간을 초 단위의 float 값으로 변환\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    # 현재 epoch의 결과와 소요 시간을 출력합니다.\n",
    "    print('epoch:', '%02d' % (epoch + 1),\n",
    "          'epoch_time =', '{:.2f} sec '.format(epoch_seconds),\n",
    "          'train_loss =', '{:.2f} '.format(train_avg_loss),\n",
    "          'train_acc =', '{:.2f} '.format(train_avg_accuracy),\n",
    "          'val_loss =', '{:.2f} '.format(val_avg_loss),\n",
    "          'val_acc =', '{:.2f} '.format(val_avg_accuracy)\n",
    "          )\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 전체 학습 종료 시각을 기록하고 전체 소요 시간을 계산합니다.\n",
    "end_time = datetime.now()  # 전체 종료 시간\n",
    "total_elapsed_time = end_time - start_time  # 전체 실행 시간 (timedelta 객체)\n",
    "# -----------------------------------------------\n",
    "\n",
    "print('Total elapsed time => ', total_elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d1ff9-4e47-4697-ad1b-0044304a5b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef4fbd-64b9-4680-bbb7-e6d2c0e6b3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f89307-4fdd-4718-98ef-21dd8cfc7cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea32fd-ba34-4208-8c44-0cbace1ec1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9cae1-29d8-4937-aea7-922b488eb447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb0bc5-741b-40d9-bd87-801c095f3ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c009f4-4bfc-437a-b248-1e037c182e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f83cf-8c5d-4503-a6fd-bd87fa8b5803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
